{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaspergroenbek98/first-first-year-project/blob/master/project1notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV3IQMyQnWOs",
        "colab_type": "code",
        "outputId": "86c932f0-361c-43cb-f6cd-2a9ad93d7c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! git clone https://github.com/kaspergroenbek98/first-first-year-project.git\n",
        "### All import calls.\n",
        "import numpy as np\n",
        "import nltk\n",
        "import csv\n",
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'first-first-year-project' already exists and is not an empty directory.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB_r1ZxGuEu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Functions\n",
        "\n",
        "### START OF VOCABULARY ###\n",
        "def generate_vocabulary(data, featureData, vocabType): #featureData = data.gender\n",
        "    '''\n",
        "    Returns a list/vocabulary of len <= \"size\" based on the vocabType and the featureColumn specified\n",
        "    '''\n",
        "    size = 2000\n",
        "    # Only get large groups to get representative data\n",
        "    major_features = nltk.FreqDist(featureData).most_common(5)\n",
        "    major_masks = [featureData == f for (f, cnt) in major_features]\n",
        "    fqs = [nltk.FreqDist(word for line in data.text[mask] for word in line.split()) for mask in major_masks]\n",
        "    return list(vocabType(data, featureData, major_features, major_masks, fqs, size))\n",
        "\n",
        "def vocab_most_common(data, featureData, major_features, major_masks, fqs, size):\n",
        "    '''\n",
        "    Returns a vocabulary checklist for each tweet to check off (True/False).\n",
        "    Prioritises the most common words for each feature\n",
        "    '''\n",
        "    vocabulary = set()\n",
        "    # get the most common words in each freq dist. zip(*...) removes the counts from fd, and updates vocabulary ONLY with the words\n",
        "    for fd in fqs:\n",
        "        vocabulary.update(list(zip(*fd.most_common(size//len(major_features))))[0])\n",
        "    return vocabulary\n",
        "\n",
        "def vocab_unique(data, fCol, major_features, major_masks, fqs, size):\n",
        "    '''\n",
        "    Returns a vocabulary checklist for each tweet to check off (True/False).\n",
        "    Prioritises words which are uncommon in other features, but common in one feature\n",
        "    '''\n",
        "    major_mask = np.array(np.array(major_masks).sum(axis=0), dtype='bool')\n",
        "    fq = nltk.FreqDist(word for line in data.text[major_mask] for word in line.split()) # Get a fq for ALL words in the major categories\n",
        "    words = [word for (word, cnt) in fq.items() if cnt >= 20] # removes rarely mentioned words which probably arent indicative of a significant trend\n",
        "    priorityArray = []\n",
        "    for i, word in enumerate(words):\n",
        "        priorityArray.append([word])\n",
        "        #divide frequency of word in that state by the tweetcount from that state, and by how often that word is used in total by all states\n",
        "        score = max(fqs[fID][word]/(int(major_features[fID][1])*fq[word]) for fID in range(len(major_masks)))\n",
        "        priorityArray[i].append(score)\n",
        "    priorityArray.sort(key = lambda x: x[1], reverse=True) # Sort them based on their best score\n",
        "    vocabulary = list(zip(*priorityArray[:size]))[0] # Removes their scores\n",
        "    return vocabulary\n",
        "\n",
        "### END OF VOCABULARY ###\n",
        "\n",
        "def cleaner(text):\n",
        "    stemmer = nltk.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "    text = text.lower() #All lowercase\n",
        "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
        "    text = re.sub('https?://[A-Za-z0-9./]+','', text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('b4', 'before', text)\n",
        "    text = re.sub(r\"amp\", \" and \", text)\n",
        "    text = re.sub('resolution', '', text)\n",
        "    text = re.sub('rt', '', text)\n",
        "    text = re.sub('years', '', text)\n",
        "    text = re.sub('new', '', text)\n",
        "    text = re.sub('year', '', text)\n",
        "    text = text.strip(' ')\n",
        "    text = ''.join(char for char in text if char.isalpha() or char == ' ')\n",
        "    text = ''.join(stemmer.stem(text)) #Stem the words using SnowballStemmer\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgs7KbInxrx",
        "colab_type": "code",
        "outputId": "902a73da-6b82-4640-e67b-af9d6c90de44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Using pandas to load the data file into a CSV.\n",
        "ISO-8859-1 is the encoding for tweets.\n",
        "\"\"\"\n",
        "df = pd.read_csv(\"first-first-year-project/data.csv\", encoding = \"ISO-8859-1\")\n",
        "#First step to cleaning the data, removing the categories we dont need.\n",
        "data = df.drop([\"other_topic\",\"resolution_topics\", \"tweet_coord\", \"tweet_created\",\"tweet_id\", \"name\", \"retweet_count\", \"tweet_date\", \"user_timezone\"], axis = 1)\n",
        "for i in range(len(data.text)): #Cleaning all the text in our data with our newly build cleaner() function.\n",
        "  data.text[i] = cleaner(data.text[i])\n",
        "\n",
        "data.text[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'finally master pa of kitchen sink'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtMB4V7tuWJ",
        "colab_type": "code",
        "outputId": "262add70-ce4c-4dbd-a64f-3a4d69483776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Vectorize using sklearn based on a vocabulary\n",
        "featureData = data.tweet_state ### CHANGE FEATURE HERE ###\n",
        "vectorizer = CountVectorizer(analyzer=\"word\", stop_words= \"english\", min_df = 20, binary= True, vocabulary = generate_vocabulary(data, featureData, vocab_unique))\n",
        "categories = list(zip(*nltk.FreqDist(featureData).most_common(5)))[0]\n",
        "mask = np.sum([featureData == category for category in categories], axis = 0, dtype='bool')\n",
        "\n",
        "# This is required to fix bugs. KFold uses indeces in the length of the array, but pandas \"hides\" arrays instead of removing them. Reset_index fixes this\n",
        "featureData = featureData[mask].reset_index()\n",
        "featureData.drop([\"index\"], axis = 1)\n",
        "featureData = featureData.tweet_state ### CHANGE FEATURE HERE ###\n",
        "\n",
        "#Here we use term frequency to downscale the importance of words occuring many times in a tweet. That way we hopefully get more weighted words. \n",
        "tfidf_transformer = TfidfTransformer()\n",
        "features = vectorizer.fit_transform(data.text[mask])\n",
        "tfidf_features = tfidf_transformer.fit_transform(features)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "# Store an object of the KFold class in a variable with shuffle=True\n",
        "k= 10\n",
        "kf = KFold(n_splits=k, shuffle=True)\n",
        "# \"\"\" \n",
        "# Loop for the models and their designated folds (1 to k)\n",
        "# and calculate the average of each of the 'k' models' accuracy\n",
        "# using the NB classifier and k-fold model class.\n",
        "# \"\"\"\n",
        "results = []\n",
        "count = 0 # sum to calculate average of model accuracies\n",
        "bigram_count = 0 # sum to calculate average of bigram model accuracies\n",
        "for i, (train, test) in enumerate(kf.split(features)): # Loop over K chunk of data splits\n",
        "    #Accuracy using term frequency. (Odd that its lower, but we do have a small data set)\n",
        "    NBmodel = MultinomialNB().fit(tfidf_features[train], featureData[train])\n",
        "    predicted = NBmodel.predict(tfidf_features[test])\n",
        "    accuracy = np.mean(predicted == featureData[test])\n",
        "    count += accuracy\n",
        "    results.append(metrics.precision_recall_fscore_support(featureData[test], predicted))\n",
        "    # A classification_report\n",
        "    print(\"Iteration no.\", i, \"\\n\")\n",
        "    print(\"Accuracy of iteration number\", i, \":\", accuracy)\n",
        "    print(\"Report based on unigrams and bigrams.\")\n",
        "    print(metrics.classification_report(featureData[test], predicted))\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "average = count/k\n",
        "\n",
        "print(\"The accuracy average of the K-fold model: \", average)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration no. 0 \n",
            "\n",
            "Accuracy of iteration number 0 : 0.36574074074074076\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.37      0.94      0.53        77\n",
            "          FL       0.00      0.00      0.00        18\n",
            "          IL       0.00      0.00      0.00        20\n",
            "          NY       0.35      0.12      0.18        59\n",
            "          TX       0.00      0.00      0.00        42\n",
            "\n",
            "    accuracy                           0.37       216\n",
            "   macro avg       0.14      0.21      0.14       216\n",
            "weighted avg       0.23      0.37      0.24       216\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 1 \n",
            "\n",
            "Accuracy of iteration number 1 : 0.3425925925925926\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.35      0.86      0.50        77\n",
            "          FL       0.00      0.00      0.00        42\n",
            "          IL       0.00      0.00      0.00        16\n",
            "          NY       0.26      0.17      0.21        41\n",
            "          TX       1.00      0.03      0.05        40\n",
            "\n",
            "    accuracy                           0.34       216\n",
            "   macro avg       0.32      0.21      0.15       216\n",
            "weighted avg       0.36      0.34      0.23       216\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 2 \n",
            "\n",
            "Accuracy of iteration number 2 : 0.33796296296296297\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.35      0.89      0.50        75\n",
            "          FL       0.00      0.00      0.00        21\n",
            "          IL       0.00      0.00      0.00        20\n",
            "          NY       0.24      0.07      0.11        70\n",
            "          TX       0.50      0.03      0.06        30\n",
            "\n",
            "    accuracy                           0.34       216\n",
            "   macro avg       0.22      0.20      0.13       216\n",
            "weighted avg       0.27      0.34      0.22       216\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 3 \n",
            "\n",
            "Accuracy of iteration number 3 : 0.3333333333333333\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.37      0.83      0.52        82\n",
            "          FL       0.00      0.00      0.00        28\n",
            "          IL       0.00      0.00      0.00        26\n",
            "          NY       0.09      0.07      0.08        44\n",
            "          TX       1.00      0.03      0.05        36\n",
            "\n",
            "    accuracy                           0.33       216\n",
            "   macro avg       0.29      0.19      0.13       216\n",
            "weighted avg       0.33      0.33      0.22       216\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 4 \n",
            "\n",
            "Accuracy of iteration number 4 : 0.3674418604651163\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.36      0.95      0.52        73\n",
            "          FL       0.00      0.00      0.00        26\n",
            "          IL       0.00      0.00      0.00        18\n",
            "          NY       0.45      0.17      0.25        59\n",
            "          TX       0.00      0.00      0.00        39\n",
            "\n",
            "    accuracy                           0.37       215\n",
            "   macro avg       0.16      0.22      0.15       215\n",
            "weighted avg       0.25      0.37      0.24       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 5 \n",
            "\n",
            "Accuracy of iteration number 5 : 0.3581395348837209\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.39      0.86      0.54        85\n",
            "          FL       0.00      0.00      0.00        26\n",
            "          IL       0.00      0.00      0.00        13\n",
            "          NY       0.11      0.07      0.09        42\n",
            "          TX       0.50      0.02      0.04        49\n",
            "\n",
            "    accuracy                           0.36       215\n",
            "   macro avg       0.20      0.19      0.13       215\n",
            "weighted avg       0.29      0.36      0.24       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 6 \n",
            "\n",
            "Accuracy of iteration number 6 : 0.29767441860465116\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.30      0.84      0.44        63\n",
            "          FL       0.00      0.00      0.00        24\n",
            "          IL       0.00      0.00      0.00        30\n",
            "          NY       0.32      0.18      0.23        56\n",
            "          TX       0.14      0.02      0.04        42\n",
            "\n",
            "    accuracy                           0.30       215\n",
            "   macro avg       0.15      0.21      0.14       215\n",
            "weighted avg       0.20      0.30      0.20       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 7 \n",
            "\n",
            "Accuracy of iteration number 7 : 0.3767441860465116\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.38      0.87      0.53        83\n",
            "          FL       0.00      0.00      0.00        27\n",
            "          IL       0.00      0.00      0.00        21\n",
            "          NY       0.35      0.17      0.23        46\n",
            "          TX       0.25      0.03      0.05        38\n",
            "\n",
            "    accuracy                           0.38       215\n",
            "   macro avg       0.20      0.21      0.16       215\n",
            "weighted avg       0.27      0.38      0.26       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 8 \n",
            "\n",
            "Accuracy of iteration number 8 : 0.2744186046511628\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.28      0.83      0.41        63\n",
            "          FL       0.00      0.00      0.00        25\n",
            "          IL       0.00      0.00      0.00        24\n",
            "          NY       0.28      0.12      0.17        59\n",
            "          TX       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.27       215\n",
            "   macro avg       0.11      0.19      0.12       215\n",
            "weighted avg       0.16      0.27      0.17       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Iteration no. 9 \n",
            "\n",
            "Accuracy of iteration number 9 : 0.30697674418604654\n",
            "Report based on unigrams and bigrams.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CA       0.30      0.90      0.45        63\n",
            "          FL       0.00      0.00      0.00        21\n",
            "          IL       0.00      0.00      0.00        23\n",
            "          NY       0.40      0.12      0.18        67\n",
            "          TX       0.50      0.02      0.05        41\n",
            "\n",
            "    accuracy                           0.31       215\n",
            "   macro avg       0.24      0.21      0.14       215\n",
            "weighted avg       0.31      0.31      0.20       215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The accuracy average of the K-fold model:  0.3361024978466839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C07yozCi9CwT",
        "colab_type": "code",
        "outputId": "52cf803e-c4bc-4921-e678-5f24fc9daaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('array1: precision, array2: recall, array3: fbetascore, array4: support')\n",
        "print(list(np.array(results).mean(axis=0).round(2)))\n",
        "NBmodel.classes_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array1: precision, array2: recall, array3: fbetascore, array4: support\n",
            "[array([0.35, 0.  , 0.  , 0.29, 0.39]), array([0.88, 0.  , 0.  , 0.13, 0.02]), array([0.49, 0.  , 0.  , 0.17, 0.03]), array([74.1, 25.8, 21.1, 54.3, 40.1])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CA', 'FL', 'IL', 'NY', 'TX'], dtype='<U2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoNtCVpU6Hur",
        "colab_type": "code",
        "outputId": "df97e7eb-b04b-4f08-ce6c-7d9b44db4e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# A perfect confusion matrix using seaborn.\n",
        "array = metrics.confusion_matrix(featureData[test], predicted, normalize='true', labels = categories)\n",
        "fig = plt.figure(figsize=(5,3))\n",
        "fig.suptitle(\"State\", fontsize= 20)\n",
        "sn.set(font_scale=1) # for x/y label size\n",
        "sn.heatmap(array, annot=True, annot_kws={\"size\": 10}, xticklabels = categories, yticklabels = categories) # annot_kws is the size of the numbers.\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAADaCAYAAAAlps6eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 360x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGkkzSHpCHv0",
        "colab_type": "code",
        "outputId": "b2a1326f-3483-450d-b0c4-bfc3013e2196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def print_top10(vectorizer, NBmodel): # Found on stackoverflow\n",
        "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    for i, class_label in enumerate(NBmodel.classes_):\n",
        "        top10 = np.argsort(NBmodel.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (class_label,\n",
        "              \" \".join(feature_names[j] for j in top10)))\n",
        "        \n",
        "print_top10(vectorizer, NBmodel)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CA: let happy going love want time sta like make stop\n",
            "FL: money going want time happy stop sta day people make\n",
            "IL: eat day let love fuck stop time like happy make\n",
            "NY: like better time going good happy people make eat stop\n",
            "TX: eat know sta let try like time better make stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceppZwZHDzzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbVaNyUnEl9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}